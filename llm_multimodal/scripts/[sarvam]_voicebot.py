# -*- coding: utf-8 -*-
"""[Sarvam] Voicebot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pJzUYE0PifRHD3S3DPr4V6sIb-OI_z1R

# üéôÔ∏è Saaras-Llama Voice Bot
### This script creates a Gradio-based web interface for a voice bot using Sarvam's Speech to Text translate (Saaras) and Meta's LLM (Llama) models.

## 1. Install Dependencies and Setup
"""

!pip install gradio ollama

# Import necessary libraries
import gradio as gr
import requests
import os

from ollama import Client

"""## 2. Create API Key and Initialize Client"""

# Initialize the client with the server's URL
client = Client(host='http://34.90.252.198:8034')

# Retrieve the API key from environment or use a default
API_KEY = os.environ.get("API_KEY", "<>")

"""## 3. Function to check which models are present in Ollama"""

def llm_selector():
    """ Fetch available models from Ollama and create a dropdown for selection. """
    ollama_models = [m['name'] for m in client.list()['models']]
    return ollama_models

ollama_models = llm_selector()

print(ollama_models)

"""## 4. Function to run `Saaras` Speech-to-text translate api"""

def transcribe_saaras(audio):
    """ Send audio file for transcription and return the transcript. """
    url = "https://api.sarvam.ai/speech-to-text-translate"
    headers = {'api-subscription-key': API_KEY}
    files = {'file': ('', open(audio, 'rb'), 'audio/wav')}
    response = requests.post(url, headers=headers, files=files)
    return response.text.lstrip('{"transcript":"').split('","language_code')[0]

"""## 5. Function to voicechat using `Saaras` and `Ollama` apis"""

# Initialize an empty list to store chat history
chat_history = []

def voicebot(audio, model):
    """ Process audio input, transcribe it, and generate a response from the LLM. """
    if audio:
        # transcribe using Saaras
        text = transcribe_saaras(audio)

        # Add user message to Chat History
        user_message = {"role": "user", "content": text}
        chat_history.append(user_message)

        # Get response from Ollama
        response = client.chat(model=model, messages=chat_history)

        # Add bot response to Chat History
        ai_message = {"role": "assistant", "content": response['message']['content']}
        chat_history.append(ai_message)

    formatted_chat_history = [(msg["content"], None) if msg["role"] == "user" else (None, msg["content"]) for msg in chat_history]
    return formatted_chat_history, None

"""#6. Define Interface using Gradio"""

# Setup the Gradio interface with Blocks
with gr.Blocks() as demo:
    gr.Markdown(f"<h1><center>üéôÔ∏è Saaras-Llama Voice Bot</center></h1>")
    with gr.Tabs():
        with gr.TabItem("Voice Bot"):
            audio = gr.Audio(label="Record Audio", sources=["microphone"], type="filepath")
            model = gr.Dropdown(label="LLM", choices=llm_selector(), value="llama3.1:latest")
            output = gr.Chatbot(label="Chat History")
            audio.change(voicebot, inputs=[audio, model], outputs=[output, audio])

# Launch the interface
demo.launch(share=True)

